{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from buffer import TraceBuf\n",
    "from common import epsilon_at, downsample, to_grayscale, checkpoint_dir, checkpoint_exists\n",
    "from common_tf import checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self, h_size, a_size, rnn_cell, scopeName):\n",
    "        self.h_size, self.a_size = h_size, a_size\n",
    "        self.scalarInput = tf.placeholder(shape=[None, 7056], dtype=tf.float32)\n",
    "        self.batch_size = tf.placeholder(dtype=tf.int32, shape=[])\n",
    "        self.trainLength = tf.placeholder(dtype=tf.int32, shape=[])\n",
    "        \n",
    "        self.frameShape = tf.constant((84, 84, 1), dtype=tf.int32)\n",
    "#         self.frames = tf.reshape(self.scalarInput, tf.concat(([self.batch_size*self.trainLength], self.frameShape), 0))\n",
    "        self.frames = tf.reshape(self.scalarInput, [-1, 84, 84, 1])\n",
    "        self.conv1 = slim.convolution2d(\n",
    "            inputs=self.frames, num_outputs=32,\n",
    "            kernel_size=(8, 8), stride=(4, 4), padding='VALID',\n",
    "            biases_initializer=None, scope=scopeName+'_conv1'\n",
    "        )\n",
    "        self.conv2 = slim.convolution2d(\n",
    "            inputs=self.conv1, num_outputs = 64,\n",
    "            kernel_size=(4, 4), stride=(2, 2), padding='VALID',\n",
    "            biases_initializer=None, scope=scopeName+'_conv2'\n",
    "        )\n",
    "        self.conv3 = slim.convolution2d(\n",
    "            inputs=self.conv2, num_outputs = 64,\n",
    "            kernel_size=(3, 3), stride=(1, 1), padding='VALID',\n",
    "            biases_initializer=None, scope=scopeName+'_conv3'\n",
    "        )\n",
    "        self.conv4 = slim.convolution2d(\n",
    "            inputs=self.conv3, num_outputs = h_size,\n",
    "            kernel_size=(7, 7), stride=(1, 1), padding='VALID',\n",
    "            biases_initializer=None, scope=scopeName+'_conv4'\n",
    "        )\n",
    "        \n",
    "        self.convFlat = tf.reshape(\n",
    "            slim.flatten(self.conv4), [self.batch_size, self.trainLength, h_size])\n",
    "        \n",
    "        self.state_init = rnn_cell.zero_state(self.batch_size, tf.float32)\n",
    "        self.rnn, self.rnn_state = tf.nn.dynamic_rnn(\n",
    "            inputs=self.convFlat, cell=rnn_cell, dtype=tf.float32,\n",
    "            initial_state=self.state_init, scope=scopeName+'_rnn'\n",
    "        )\n",
    "        self.rnn = tf.reshape(self.rnn, shape=[-1, h_size])\n",
    "        \n",
    "        self.streamA, self.streamV = tf.split(self.rnn, 2, axis=1)\n",
    "        \n",
    "        self.AW = tf.Variable(tf.random_normal([h_size//2, a_size]))\n",
    "        self.VW = tf.Variable(tf.random_normal([h_size//2, 1]))\n",
    "        self.A = tf.matmul(self.streamA, self.AW)\n",
    "        self.V = tf.matmul(self.streamV, self.VW)\n",
    "        \n",
    "        self.salience = tf.gradients(self.A, self.scalarInput)\n",
    "        \n",
    "        self.Qout = self.V + \\\n",
    "            (self.A - tf.reduce_mean(self.A, axis=1, keepdims=True))\n",
    "        self.predict = tf.argmax(self.Qout, 1)\n",
    "        self.action = self.predict[-1]\n",
    "        \n",
    "        self.targetQ = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions, a_size, dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(self.Qout * self.actions_onehot,\n",
    "                               reduction_indices=1)\n",
    "        \n",
    "        # only train on first half of trace per Lample & Chatlot 2016\n",
    "        self.mask = tf.concat((tf.zeros((self.batch_size, self.trainLength//2)),\n",
    "                               tf.ones((self.batch_size, self.trainLength//2))), 1)\n",
    "        self.mask = tf.reshape(self.mask, [-1])\n",
    "        \n",
    "        self.loss = tf.losses.huber_loss(self.Q * self.mask, self.targetQ * self.mask)\n",
    "        tf.summary.histogram('loss', self.loss)\n",
    "        \n",
    "        self.trainer = tf.train.RMSPropOptimizer(0.00025, momentum=0.95, epsilon=0.01)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    return downsample(to_grayscale(s[8:-12]), (84,84)).reshape((7056,))\n",
    "\n",
    "def reset(env, buf, noop_max=30):\n",
    "    if buf.trans_cache: buf._flush()\n",
    "    S = [preprocess(env.reset())]\n",
    "    life = None\n",
    "    for _ in range(np.random.randint(noop_max)):\n",
    "        s, r, t, l = env.step(0)\n",
    "        s, life = preprocess(s), l['ale.lives']\n",
    "        if t: return reset(env, buf, noop_max)\n",
    "        buf.append_trans((S[-1],0,r,s,t))\n",
    "        S.append(s)\n",
    "    return S, life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getTargetUpdateOps(tfVars):\n",
    "    # tfVars consists of all trainble TF Variables\n",
    "    # where the first half is from the main network\n",
    "    #  and the second half is from the target network\n",
    "    # RETURNS: list of operations which when run, \n",
    "    #          updates the target network with main network's values\n",
    "    return [vt.assign(vm.value()) \n",
    "            for i, (vm, vt) in enumerate(zip(tfVars[:len(tfVars)//2],\n",
    "                                             tfVars[len(tfVars)//2:]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTarget(op_holder, sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)\n",
    "    total_vars = len(tf.trainable_variables())\n",
    "    a = tf.trainable_variables()[0].eval(session=sess)\n",
    "    b = tf.trainable_variables()[total_vars//2].eval(session=sess)\n",
    "    if a.all() == b.all():\n",
    "        print(\"Target Set Success\")\n",
    "    else:\n",
    "        print(\"Target Set Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(trace_length, h_size=512, update_freq=4, ckpt_freq=10000, batch_size=32, env_name='SpaceInvaders', total_iteration=5e7, pretrain_steps=50000):\n",
    "    global exp_buf\n",
    "    env_name += 'NoFrameskip-v4'\n",
    "    identity = 'stack={},env={},mod={}'.format(trace_length, env_name, 'drqn')\n",
    "    \n",
    "    \n",
    "    env = gym.make(env_name)\n",
    "    a_size = env.action_space.n\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    cell  = tf.nn.rnn_cell.LSTMCell(num_units=h_size)\n",
    "    cellT = tf.nn.rnn_cell.LSTMCell(num_units=h_size)\n",
    "    mainQN   = Qnetwork(h_size, a_size, cell, 'main')\n",
    "    targetQN = Qnetwork(h_size, a_size, cellT, 'target')\n",
    "    init = tf.global_variables_initializer()\n",
    "    updateOps = getTargetUpdateOps(tf.trainable_variables())\n",
    "    saver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    summary_writer = tf.summary.FileWriter('./log/' + identity, sess.graph)\n",
    "    \n",
    "    \n",
    "    if checkpoint_exists(identity):\n",
    "        (exp_buf, env, last_iteration, is_done, \n",
    "         prev_life_count, prev_action,\n",
    "         prev_action_taken, state) = load_checkpoint(sess, saver, identity)\n",
    "    else:\n",
    "        exp_buf = TraceBuf(trace_length, size=50000)\n",
    "        last_iteration = 1 - pretrain_steps\n",
    "        is_done = True\n",
    "        prev_life_count = None\n",
    "        prev_action, prev_action_taken = 0, 0\n",
    "        state = None\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    updateTarget(updateOps, sess)\n",
    "    \n",
    "#     print((exp_buf, env, last_iteration, is_done, \n",
    "#          prev_life_count, prev_action,\n",
    "#          prev_action_taken, state))\n",
    "#     print(last_iteration)\n",
    "    \n",
    "    for i in range(last_iteration, int(total_iteration)):\n",
    "        if is_done:\n",
    "            exp_buf._flush()\n",
    "            S, prev_life_count = reset(env, exp_buf)\n",
    "            state, action = sess.run((mainQN.rnn_state, mainQN.action), feed_dict={\n",
    "                mainQN.scalarInput: np.vstack(np.array(S)/255.0),\n",
    "                mainQN.trainLength: len(S),\n",
    "                mainQN.state_init: (np.zeros((1, h_size)),) * 2,\n",
    "                mainQN.batch_size: 1\n",
    "            })\n",
    "            \n",
    "        \n",
    "        S = [S[-1]]\n",
    "        for _ in range(4):\n",
    "            s, r, is_done, info = env.step(action)\n",
    "            s, life_count = preprocess(s), info['ale.lives']\n",
    "            exp_buf.append_trans((\n",
    "                S[-1], action, np.sign(r), s,\n",
    "                (prev_life_count and life_count < prev_life_count or is_done)\n",
    "            ))\n",
    "            S.append(s)\n",
    "            prev_life_count = life_count\n",
    "            \n",
    "        feed = {\n",
    "            mainQN.scalarInput: np.vstack(np.array(S[1:])/255.0),\n",
    "            mainQN.trainLength: 4,\n",
    "            mainQN.state_init: state,\n",
    "            mainQN.batch_size: 1\n",
    "        }\n",
    "        if np.random.random() < epsilon_at(i):\n",
    "            action = env.action_space.sample()\n",
    "            state = sess.run(mainQN.rnn_state, feed_dict=feed)\n",
    "        else:\n",
    "            action, state = sess.run((mainQN.action, mainQN.rnn_state),\\\n",
    "                                        feed_dict=feed)\n",
    "        \n",
    "        \n",
    "        if not i: start_time = time.time()\n",
    "            \n",
    "        if i <= 0: continue\n",
    "            \n",
    "        if not i % ckpt_freq:\n",
    "            checkpoint(sess, saver, identity,\n",
    "                       exp_buf, env, last_iteration, is_done, \n",
    "                       prev_life_count, prev_action,\n",
    "                       prev_action_taken, state)\n",
    "\n",
    "        if not i % (update_freq * 1000):\n",
    "            updateTarget(updateOps, sess)\n",
    "#             print(evaluate(sess, mainQN, env_name))\n",
    "            print(i)\n",
    "            cur_time = time.time()\n",
    "            print('took', cur_time-start_time, 'second to do', str(update_freq*1000), 'iterations')\n",
    "            start_time = cur_time\n",
    "\n",
    "        if not i % update_freq:\n",
    "            # train batch\n",
    "            summaryOps = tf.summary.merge_all()\n",
    "            \n",
    "            state_train = (np.zeros((batch_size, h_size)),) * 2\n",
    "\n",
    "            trainBatch = exp_buf.sample_traces(batch_size)\n",
    "            \n",
    "\n",
    "            Q1 = sess.run(mainQN.predict, feed_dict={\n",
    "                mainQN.scalarInput: np.vstack(trainBatch[:,3]/255.0),\n",
    "                mainQN.trainLength: trace_length,\n",
    "                mainQN.state_init: state_train,\n",
    "                mainQN.batch_size: batch_size\n",
    "            })\n",
    "            Q2 = sess.run(targetQN.Qout, feed_dict={\n",
    "                targetQN.scalarInput: np.vstack(trainBatch[:,3]/255.0),\n",
    "                targetQN.trainLength: trace_length,\n",
    "                targetQN.state_init: state_train,\n",
    "                targetQN.batch_size: batch_size\n",
    "            })\n",
    "            end_multiplier = - (trainBatch[:,4] - 1)\n",
    "            doubleQ = Q2[range(batch_size * trace_length), Q1]\n",
    "            targetQ = trainBatch[:,2] + (0.99 * doubleQ * end_multiplier)\n",
    "\n",
    "            print(trainBatch[:,0].shape)\n",
    "            _, loss, summary = sess.run((mainQN.updateModel, mainQN.loss, summaryOps), feed_dict={\n",
    "                mainQN.scalarInput:np.vstack(trainBatch[:,0]/255.0),\n",
    "                mainQN.targetQ: targetQ,\n",
    "                mainQN.actions: trainBatch[:,1],\n",
    "                mainQN.trainLength: trace_length,\n",
    "                mainQN.state_init: state_train,\n",
    "                mainQN.batch_size: batch_size\n",
    "            })\n",
    "\n",
    "            print(summary)\n",
    "            summary_writer.add_summary(summary, i)\n",
    "            \n",
    "        \n",
    "        \n",
    "    sess.close()\n",
    "    checkpoint(sess, saver, identity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def evaluate(sess, mainQN, env_name, action_repeat=6, scenario_count=3, is_render=False):\n",
    "    start_time = time.time()\n",
    "    env = gym.make(env_name)\n",
    "    # step 6 frame with same action, and use trace size = 6\n",
    "    def get_action(S):\n",
    "        return sess.run(mainQN.action, feed_dict={\n",
    "            mainQN.scalarInput: np.vstack(np.array(S)/255.0),\n",
    "            mainQN.trainLength: len(S),\n",
    "            mainQN.state_init: (np.zeros((1, mainQN.h_size)),) * 2,\n",
    "            mainQN.batch_size: 1\n",
    "        })\n",
    "    \n",
    "    def run_scenario():\n",
    "        S, R, t = [preprocess(env.reset())], 0, 0\n",
    "        noop = np.random.randint(30)\n",
    "        for i in range(noop):\n",
    "            frame, r, t, _ = env.step(0)\n",
    "            S += (preprocess(frame),)\n",
    "            R += r\n",
    "        action = get_action(S)\n",
    "        while not t:\n",
    "            S.clear()\n",
    "            for i in range(action_repeat):\n",
    "#                 print(action)\n",
    "                frame, r, t, _ = env.step(action)\n",
    "                R += r\n",
    "                S += (preprocess(frame),)\n",
    "                if is_render: env.render()\n",
    "            action = get_action(S)\n",
    "        return R\n",
    "\n",
    "    res = np.array([run_scenario() for _ in range(scenario_count)])\n",
    "    print(time.time()-start_time, 'seconds to evaluate')\n",
    "    return np.mean(res), np.std(res)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Set Success\n",
      "(320,)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_5' with dtype float and shape [?,7056]\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[?,7056], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: huber_loss/value/_119 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_275_huber_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_5', defined at:\n  File \"/home/diyiw/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/diyiw/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-0f72668b21f6>\", line 1, in <module>\n    train(10, pretrain_steps=8000)\n  File \"<ipython-input-6-168d4c146d28>\", line 15, in train\n    targetQN = Qnetwork(h_size, a_size, cellT, 'target')\n  File \"<ipython-input-2-81ede5929514>\", line 4, in __init__\n    self.scalarInput = tf.placeholder(shape=[None, 7056], dtype=tf.float32)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4925, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_5' with dtype float and shape [?,7056]\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[?,7056], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: huber_loss/value/_119 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_275_huber_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_5' with dtype float and shape [?,7056]\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[?,7056], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: huber_loss/value/_119 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_275_huber_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0f72668b21f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-168d4c146d28>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trace_length, h_size, update_freq, ckpt_freq, batch_size, env_name, total_iteration, pretrain_steps)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainLength\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrace_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_init\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             })\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_5' with dtype float and shape [?,7056]\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[?,7056], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: huber_loss/value/_119 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_275_huber_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_5', defined at:\n  File \"/home/diyiw/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/diyiw/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-0f72668b21f6>\", line 1, in <module>\n    train(10, pretrain_steps=8000)\n  File \"<ipython-input-6-168d4c146d28>\", line 15, in train\n    targetQN = Qnetwork(h_size, a_size, cellT, 'target')\n  File \"<ipython-input-2-81ede5929514>\", line 4, in __init__\n    self.scalarInput = tf.placeholder(shape=[None, 7056], dtype=tf.float32)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4925, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/diyiw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_5' with dtype float and shape [?,7056]\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[?,7056], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: huber_loss/value/_119 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_275_huber_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "train(10, pretrain_steps=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<buffer.TraceBuf at 0x7f1e31b0e208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = exp_buf.sample_traces(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(traces[:,0]/255.0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('SpaceInvadersNoFrameskip-v4')\n",
    "# s = env.reset()\n",
    "# p = preprocess(s)\n",
    "# print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
