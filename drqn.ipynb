{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from buffer import TraceBuf\n",
    "from common import epsilon_at, downsample, to_grayscale, checkpoint_dir, checkpoint_exists\n",
    "from common_tf import checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self, h_size, a_size, rnn_cell, scopeName):\n",
    "        self.h_size, self.a_size = h_size, a_size\n",
    "        self.scalarInput = tf.placeholder(shape=[None, 7056], dtype=tf.float32)\n",
    "        self.batch_size = tf.placeholder(dtype=tf.int32, shape=[])\n",
    "        self.trainLength = tf.placeholder(dtype=tf.int32, shape=[])\n",
    "        \n",
    "        self.frameShape = tf.constant((84, 84, 1), dtype=tf.int32)\n",
    "#         self.frames = tf.reshape(self.scalarInput, tf.concat(([self.batch_size*self.trainLength], self.frameShape), 0))\n",
    "        self.frames = tf.reshape(self.scalarInput, [-1, 84, 84, 1])\n",
    "        self.conv1 = slim.convolution2d(\n",
    "            inputs=self.frames, num_outputs=32,\n",
    "            kernel_size=(8, 8), stride=(4, 4), padding='VALID',\n",
    "            biases_initializer=None, scope=scopeName+'_conv1'\n",
    "        )\n",
    "        self.conv2 = slim.convolution2d(\n",
    "            inputs=self.conv1, num_outputs = 64,\n",
    "            kernel_size=(4, 4), stride=(2, 2), padding='VALID',\n",
    "            biases_initializer=None, scope=scopeName+'_conv2'\n",
    "        )\n",
    "        self.conv3 = slim.convolution2d(\n",
    "            inputs=self.conv2, num_outputs = 64,\n",
    "            kernel_size=(3, 3), stride=(1, 1), padding='VALID',\n",
    "            biases_initializer=None, scope=scopeName+'_conv3'\n",
    "        )\n",
    "        self.conv4 = slim.convolution2d(\n",
    "            inputs=self.conv3, num_outputs = h_size,\n",
    "            kernel_size=(7, 7), stride=(1, 1), padding='VALID',\n",
    "            biases_initializer=None, scope=scopeName+'_conv4'\n",
    "        )\n",
    "        \n",
    "        self.convFlat = tf.reshape(\n",
    "            slim.flatten(self.conv4), [self.batch_size, self.trainLength, h_size])\n",
    "        \n",
    "        self.state_init = rnn_cell.zero_state(self.batch_size, tf.float32)\n",
    "        self.rnn, self.rnn_state = tf.nn.dynamic_rnn(\n",
    "            inputs=self.convFlat, cell=rnn_cell, dtype=tf.float32,\n",
    "            initial_state=self.state_init, scope=scopeName+'_rnn'\n",
    "        )\n",
    "        self.rnn = tf.reshape(self.rnn, shape=[-1, h_size])\n",
    "        \n",
    "        self.streamA, self.streamV = tf.split(self.rnn, 2, axis=1)\n",
    "        \n",
    "        self.AW = tf.Variable(tf.random_normal([h_size//2, a_size]))\n",
    "        self.VW = tf.Variable(tf.random_normal([h_size//2, 1]))\n",
    "        self.A = tf.matmul(self.streamA, self.AW)\n",
    "        self.V = tf.matmul(self.streamV, self.VW)\n",
    "        \n",
    "        self.salience = tf.gradients(self.A, self.scalarInput)\n",
    "        \n",
    "        self.Qout = self.V + \\\n",
    "            (self.A - tf.reduce_mean(self.A, axis=1, keepdims=True))\n",
    "        self.predict = tf.argmax(self.Qout, 1)\n",
    "        self.action = self.predict[-1]\n",
    "        \n",
    "        \n",
    "        self.targetQ = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions, a_size, dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(self.Qout * self.actions_onehot,\n",
    "                               reduction_indices=1)\n",
    "        \n",
    "        # only train on first half of trace per Lample & Chatlot 2016\n",
    "        self.mask = tf.concat((tf.zeros((self.batch_size, self.trainLength//2)),\n",
    "                               tf.ones((self.batch_size, self.trainLength//2))), 1)\n",
    "        self.mask = tf.reshape(self.mask, [-1])\n",
    "        \n",
    "        self.loss = tf.losses.huber_loss(self.Q * self.mask, self.targetQ * self.mask)\n",
    "        \n",
    "        if scopeName == 'main':\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            tf.summary.histogram('Q', self.Qout)\n",
    "            tf.summary.histogram('hidden', self.rnn_state)\n",
    "            \n",
    "        self.trainer = tf.train.RMSPropOptimizer(0.00025, momentum=0.95, epsilon=0.01)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    return downsample(to_grayscale(s[8:-12]), (84,84)).reshape((7056,))\n",
    "\n",
    "def reset(env, buf, noop_max=30):\n",
    "    if buf.trans_cache: buf._flush()\n",
    "    S = [preprocess(env.reset())]\n",
    "    life = None\n",
    "    for _ in range(np.random.randint(noop_max)):\n",
    "        s, r, t, l = env.step(0)\n",
    "        s, life = preprocess(s), l['ale.lives']\n",
    "        if t: return reset(env, buf, noop_max)\n",
    "        buf.append_trans((S[-1],0,r,s,t))\n",
    "        S.append(s)\n",
    "    return S, life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getTargetUpdateOps(tfVars):\n",
    "    # tfVars consists of all trainble TF Variables\n",
    "    # where the first half is from the main network\n",
    "    #  and the second half is from the target network\n",
    "    # RETURNS: list of operations which when run, \n",
    "    #          updates the target network with main network's values\n",
    "    return [vt.assign(vm.value()) \n",
    "            for i, (vm, vt) in enumerate(zip(tfVars[:len(tfVars)//2],\n",
    "                                             tfVars[len(tfVars)//2:]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTarget(op_holder, sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)\n",
    "    total_vars = len(tf.trainable_variables())\n",
    "    a = tf.trainable_variables()[0].eval(session=sess)\n",
    "    b = tf.trainable_variables()[total_vars//2].eval(session=sess)\n",
    "    if a.all() == b.all():\n",
    "        print(\"Target Set Success\")\n",
    "    else:\n",
    "        print(\"Target Set Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(trace_length, h_size=512, update_freq=4, ckpt_freq=10000, batch_size=32, env_name='SpaceInvaders', total_iteration=5e7, pretrain_steps=50000):\n",
    "    global exp_buf\n",
    "    env_name += 'NoFrameskip-v4'\n",
    "    identity = 'stack={},env={},mod={}'.format(trace_length, env_name, 'drqn')\n",
    "    \n",
    "    \n",
    "    env = gym.make(env_name)\n",
    "    a_size = env.action_space.n\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    cell  = tf.nn.rnn_cell.LSTMCell(num_units=h_size)\n",
    "    cellT = tf.nn.rnn_cell.LSTMCell(num_units=h_size)\n",
    "    mainQN   = Qnetwork(h_size, a_size, cell, 'main')\n",
    "    targetQN = Qnetwork(h_size, a_size, cellT, 'target')\n",
    "    init = tf.global_variables_initializer()\n",
    "    updateOps = getTargetUpdateOps(tf.trainable_variables())\n",
    "    saver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    summary_writer = tf.summary.FileWriter('./log/' + identity, sess.graph)\n",
    "    \n",
    "    \n",
    "    if checkpoint_exists(identity):\n",
    "        (exp_buf, env, last_iteration, is_done, \n",
    "         prev_life_count, prev_action,\n",
    "         prev_action_taken, state, S) = load_checkpoint(sess, saver, identity)\n",
    "    else:\n",
    "        exp_buf = TraceBuf(trace_length, size=50000)\n",
    "        last_iteration = 1 - pretrain_steps\n",
    "        is_done = True\n",
    "        prev_life_count = None\n",
    "        prev_action, prev_action_taken = 0, 0\n",
    "        state = None\n",
    "    \n",
    "    is_done = True\n",
    "    sess.run(init)\n",
    "    \n",
    "    updateTarget(updateOps, sess)\n",
    "    summaryOps = tf.summary.merge_all()\n",
    "    \n",
    "#     print((exp_buf, env, last_iteration, is_done, \n",
    "#          prev_life_count, prev_action,\n",
    "#          prev_action_taken, state))\n",
    "#     print(last_iteration)\n",
    "    \n",
    "    for i in range(last_iteration, int(total_iteration)):\n",
    "        if is_done:\n",
    "            exp_buf._flush()\n",
    "            S, prev_life_count = reset(env, exp_buf)\n",
    "            state, action = sess.run((mainQN.rnn_state, mainQN.action), feed_dict={\n",
    "                mainQN.scalarInput: np.vstack(np.array(S)/255.0),\n",
    "                mainQN.trainLength: len(S),\n",
    "                mainQN.state_init: (np.zeros((1, h_size)),) * 2,\n",
    "                mainQN.batch_size: 1\n",
    "            })\n",
    "            \n",
    "        \n",
    "        S = [S[-1]]\n",
    "        for _ in range(4):\n",
    "            s, r, is_done, info = env.step(action)\n",
    "            s, life_count = preprocess(s), info['ale.lives']\n",
    "            exp_buf.append_trans((\n",
    "                S[-1], action, np.sign(r), s,\n",
    "                (prev_life_count and life_count < prev_life_count or is_done)\n",
    "            ))\n",
    "            S.append(s)\n",
    "            prev_life_count = life_count\n",
    "            \n",
    "        feed = {\n",
    "            mainQN.scalarInput: np.vstack(np.array(S[1:])/255.0),\n",
    "            mainQN.trainLength: 4,\n",
    "            mainQN.state_init: state,\n",
    "            mainQN.batch_size: 1\n",
    "        }\n",
    "        if np.random.random() < epsilon_at(i):\n",
    "            action = env.action_space.sample()\n",
    "            state = sess.run(mainQN.rnn_state, feed_dict=feed)\n",
    "        else:\n",
    "            action, state = sess.run((mainQN.action, mainQN.rnn_state),\\\n",
    "                                        feed_dict=feed)\n",
    "        \n",
    "        \n",
    "        if not i: start_time = time.time()\n",
    "            \n",
    "        if i <= 0: continue\n",
    "            \n",
    "        if not i % ckpt_freq:\n",
    "            checkpoint(sess, saver, identity,\n",
    "                       exp_buf, env, last_iteration, is_done, \n",
    "                       prev_life_count, prev_action,\n",
    "                       prev_action_taken, state, S)\n",
    "\n",
    "        if not i % (update_freq * 1000):\n",
    "            updateTarget(updateOps, sess)\n",
    "#             print(evaluate(sess, mainQN, env_name))\n",
    "            print(i)\n",
    "            cur_time = time.time()\n",
    "            print('took', cur_time-start_time, 'second to do', str(update_freq*1000), 'iterations')\n",
    "            start_time = cur_time\n",
    "\n",
    "        if not i % update_freq:\n",
    "            # train batch\n",
    "            \n",
    "            state_train = (np.zeros((batch_size, h_size)),) * 2\n",
    "\n",
    "            trainBatch = exp_buf.sample_traces(batch_size)\n",
    "            \n",
    "\n",
    "            Q1 = sess.run(mainQN.predict, feed_dict={\n",
    "                mainQN.scalarInput: np.vstack(trainBatch[:,3]/255.0),\n",
    "                mainQN.trainLength: trace_length,\n",
    "                mainQN.state_init: state_train,\n",
    "                mainQN.batch_size: batch_size\n",
    "            })\n",
    "            Q2 = sess.run(targetQN.Qout, feed_dict={\n",
    "                targetQN.scalarInput: np.vstack(trainBatch[:,3]/255.0),\n",
    "                targetQN.trainLength: trace_length,\n",
    "                targetQN.state_init: state_train,\n",
    "                targetQN.batch_size: batch_size\n",
    "            })\n",
    "            end_multiplier = - (trainBatch[:,4] - 1)\n",
    "            doubleQ = Q2[range(batch_size * trace_length), Q1]\n",
    "            targetQ = trainBatch[:,2] + (0.99 * doubleQ * end_multiplier)\n",
    "            \n",
    "            _, loss, summary = sess.run((mainQN.updateModel, mainQN.loss, mainQN.loss_sum), feed_dict={\n",
    "                mainQN.scalarInput:np.vstack(trainBatch[:,0]/255.0),\n",
    "                mainQN.targetQ: targetQ,\n",
    "                mainQN.actions: trainBatch[:,1],\n",
    "                mainQN.trainLength: trace_length,\n",
    "                mainQN.state_init: state_train,\n",
    "                mainQN.batch_size: batch_size\n",
    "            })\n",
    "            \n",
    "            if not i % summary_freq:\n",
    "                summary_writer.add_summary(summary, i)\n",
    "            \n",
    "        \n",
    "        \n",
    "    sess.close()\n",
    "    checkpoint(sess, saver, identity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def evaluate(sess, mainQN, env_name, action_repeat=6, scenario_count=3, is_render=False):\n",
    "    start_time = time.time()\n",
    "    env = gym.make(env_name)\n",
    "    # step 6 frame with same action, and use trace size = 6\n",
    "    def get_action(S):\n",
    "        return sess.run(mainQN.action, feed_dict={\n",
    "            mainQN.scalarInput: np.vstack(np.array(S)/255.0),\n",
    "            mainQN.trainLength: len(S),\n",
    "            mainQN.state_init: (np.zeros((1, mainQN.h_size)),) * 2,\n",
    "            mainQN.batch_size: 1\n",
    "        })\n",
    "    \n",
    "    def run_scenario():\n",
    "        S, R, t = [preprocess(env.reset())], 0, 0\n",
    "        noop = np.random.randint(30)\n",
    "        for i in range(noop):\n",
    "            frame, r, t, _ = env.step(0)\n",
    "            S += (preprocess(frame),)\n",
    "            R += r\n",
    "        action = get_action(S)\n",
    "        while not t:\n",
    "            S.clear()\n",
    "            for i in range(action_repeat):\n",
    "#                 print(action)\n",
    "                frame, r, t, _ = env.step(action)\n",
    "                R += r\n",
    "                S += (preprocess(frame),)\n",
    "                if is_render: env.render()\n",
    "            action = get_action(S)\n",
    "        return R\n",
    "\n",
    "    res = np.array([run_scenario() for _ in range(scenario_count)])\n",
    "    print(time.time()-start_time, 'seconds to evaluate')\n",
    "    return np.mean(res), np.std(res)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpts/stack=10,env=SpaceInvadersNoFrameskip-v4,mod=drqn/tf_vars.ckpt\n",
      "Target Set Success\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'S' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2512ceaabd2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1b1467cc7fe8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trace_length, h_size, update_freq, ckpt_freq, batch_size, env_name, total_iteration, pretrain_steps)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'S' referenced before assignment"
     ]
    }
   ],
   "source": [
    "train(10, pretrain_steps=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('SpaceInvadersNoFrameskip-v4')\n",
    "# s = env.reset()\n",
    "# p = preprocess(s)\n",
    "# print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
